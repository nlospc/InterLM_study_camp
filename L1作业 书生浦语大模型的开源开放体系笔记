## 书生浦语大模型的开源开放体系笔记
### 开源之路

| 模型           | 时间        | 介绍                                                    | 成就                   |
| ------------ | --------- | ----------------------------------------------------- | -------------------- |
| internLM-7B  | 2023.7.6  | 适合个人使用，超轻量级，用于端侧应用或开发者上手学习                            | 7B模型免费开源，发布全链条开源工具体系 |
| internLM-20B | 2023.9.20 | 适合小型团队，模型轻便，适合轻量级研究和应用                                | 开源工具链升级              |
| internLM2    | 2024.1.17 | 综合性能更强劲，可以有效支撑复杂使用场景                                  | 开源                   |
| internLM2.5  | 2024.7月   | - 上下文记忆能力达到100万级别<br>- 推理能力领先<br>- 自主规划和搜索，完成复杂任务<br> | 开源<br>- 典型场景接近GPT-4  |
##### 谱系
- InternLM-XComposer  灵笔
- InternLM-Math  数学
- InternLM-WQX  文曲星
![[Pasted image 20240829104431.png]]

#### 技术思想

- 数据驱动模型性能
- 高质量合成数据策略：规则构造、模型数据扩充、基于反馈的数据生成

#### 工具与框架

- **数据**：书胜万卷语料库、30多个模态数据集
- **预训练框架**：InturnEvil，显存优化、分布式训练
- **微调框架**：XTurner，支持增量预训练、多模态微调
- **评测**：Open Compass，大模型评测国标主要单位
- **部署**：LM Deploy，支持多种开源模型部署
- **智能体框架**：Legend，支持多种智能体构建方案

#### 应用示例

- **大海捞针实验**：模型在超长上下文中定位信息的能力
- **Mind Search**：基于AI的搜索引擎，模拟人脑思维逻辑
- **茴香豆**：企业级知识库构建工具，支持RAG和知识图谱

#### 解决复杂问题的思路
##### 人的思路
用户需求-> 问题分析->思维路径拆解->相关信息检索->内容整合->问题回复

##### 书生浦语

![[Pasted image 20240829103810.png]]

#### 开源模型体系的介绍
##### 1、数据
![[Pasted image 20240829104723.png]]
##### 2、 预训练
![[Pasted image 20240829104750.png]]
##### 3、微调
![[Pasted image 20240829104825.png]]
同时适配多种生态
显存优化
##### 4、部署
![[Pasted image 20240829105010.png]]
#####  5、评测
![[Pasted image 20240829104938.png]]
#####  6、应用
![[Pasted image 20240829105032.png]]



#### 社区贡献

- 开源社区贡献者参与模型迭代和工具开发
- Label LLM：简化NLP任务标注流程
- Minor U：文档解析工具，支持多种文档格式

#### 结语

- 书生·浦语大模型实战营已开展三期，学员开发毕业项目
- 高质量开源赋能，推动创新
